[
  {
    "objectID": "datacleaning.html",
    "href": "datacleaning.html",
    "title": "2  Data Cleaning",
    "section": "",
    "text": "2.1 Loading the Dataset\n# importing libraries\nimport pandas as pd \n\n# adding gitignore \n# .gitignore\n\n# loading the data set\ndf1 = pd.read_csv(\"./season1.csv\")\ndf2 = pd.read_csv(\"./season2.csv\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Cleaning</span>"
    ]
  },
  {
    "objectID": "dataviz.html",
    "href": "dataviz.html",
    "title": "4  Data Visualization",
    "section": "",
    "text": "5 Graph 1: Looking at the Percentages of Total Player Load separate by position, for each period\n\n# Importing libraries\nimport pandas as pd \nimport matplotlib.pyplot as plt\n\n# Loading in cleaned data set \ndf1 = pd.read_csv(\"./season1_cleaned.csv\")\n\nTo get the data ready for our pie charts, we need to separate the one dataframe by Period to make new two dataframes: p1 and p2. For the two new dataframes, we wil use the groupby method to group the data by Position and then find the average of the Total Player Load for each position.\n\n# Separate df1 into dataframes for period 1 and for period 2\np1 = df1[df1['Period'] == 'Period 1'].copy().reset_index(drop=True)\np2 = df1[df1['Period'] == 'Period 2'].copy().reset_index(drop=True)\n\n# Take average of `Total Player Load` by `Position` for each period dataframe\n# Grouping by `Position`, then taking the mean of `Total Player Load`, then resetting the index \np1_avg = p1.groupby(['Position'])['Total Player Load'].mean().reset_index()\np2_avg = p2.groupby(['Position'])['Total Player Load'].mean().reset_index()\n\n# Print dataframes\nprint(p1_avg,\"\\n\")\nprint(p2_avg)\n\n  Position  Total Player Load\n0   Center         109.076500\n1  Forward         216.843042\n2    Guard         267.258140 \n\n  Position  Total Player Load\n0   Center          88.344647\n1  Forward         238.046535\n2    Guard         278.306542\n\n\nNow3 that we have the averages, we will divide each position’s Total Player Load by the sum of all positions’ Total Player Load to get the percentage. This percentage will be stored in a new column, Proportion.\n\n# Add a new column, Proportion, for each position's TPL for each period \np1_avg['Proportion'] = p1_avg['Total Player Load'] / p1_avg['Total Player Load'].sum()\np2_avg['Proportion'] = p2_avg['Total Player Load'] / p2_avg['Total Player Load'].sum()\n\n# Print dataframes w/ new column\nprint(p1_avg, \"\\n\")\nprint(p2_avg)\n\n  Position  Total Player Load  Proportion\n0   Center         109.076500    0.183885\n1  Forward         216.843042    0.365562\n2    Guard         267.258140    0.450553 \n\n  Position  Total Player Load  Proportion\n0   Center          88.344647    0.146097\n1  Forward         238.046535    0.393662\n2    Guard         278.306542    0.460241\n\n\nTo plot our donut charts, we will use the plot.pie method. Using subplots, we can create two donut charts side by side to demonstrate the percentages of Total Player Load for each position in each period.\n\n# Make color dict for positions\ncolors = {'Guard': '#E57200', 'Forward': '#232D4B', 'Center': '#C8CBD2'}\n\n# Make subplots, 1 row and 2 columns \nfig, ax = plt.subplots(1, 2, figsize=(9, 5))\n\n# Graphing Period 1 as ax[0], aka first subplot \n# the wedgeprops argument is used to give the hole in the center, the autopct argument is used to display the percentages, the pctdistance argument is used to change the distance of the percentage text\n# the textprops argument is used to change the font color and size, the startangle argument is used to rotate the chart, and the colors argument is used to change the colors of the wedges based on the position\nax[0].pie(p1_avg['Proportion'], labels=None, wedgeprops=dict(width=0.5), autopct='%1.1f%%', pctdistance=0.7, textprops={'color': 'white', 'fontsize': '12'}, startangle=90, colors=[colors[pos] for pos in p1_avg['Position']])\n# the annotate argument is used to add text to the center of the donut chart\nax[0].annotate('Period 1', xy=(0, 0), fontsize=15, ha='center')\n\n# Graphing Period 2 as ax[1], aka the second subplot\n# the arguments are the same as above, but with data from p2_avg \nax[1].pie(p2_avg['Proportion'], labels=None, wedgeprops=dict(width=0.5), autopct='%1.1f%%', pctdistance=0.7, textprops={'color': 'white', 'fontsize': '12'}, startangle=90, colors=[colors[pos] for pos in p2_avg['Position']])\nax[1].annotate('Period 2', xy=(0, 0), fontsize=15, ha='center')\n\n# Adding a title \nfig.suptitle('Guards Contribute A Higher Proportion of the Total Player Load', fontsize=18)\n\n# Adding a legend, and setting the location, font size, and position \nfig.legend(p1_avg['Position'], loc='center', bbox_to_anchor=(0.5, 0.8), title='Position', fontsize=12)\n\n# Making a tight layout and displaying the plot\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n6 Graph 2: Looking at Explosive efforts, ima accel/decels, and ima jump band counts (med, high, low)\n\n# Importing libraries for graph 2\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.dates as mdates\nfrom matplotlib.patches import Patch\n\nThere must be setup in logistics like turning Date string from the dataset into a datetime structure and filtering the data just for that of Athlete H:\n\n# Obtain `Date` from df1 and turn into datetime object through pandas\ndf1['Date'] = pd.to_datetime(df1['Date'], format='%m/%d/%y')\n\n# Not wanting to work straight on df1, I will create a copy of df1 to manipulate for this graph:\ndf1_copy = df1.copy()\n\n# sort for just Athlete H (athlete in Season 1 with highest incline in player load)\ndf1_copy = df1_copy[df1_copy['About'] == 'Athlete H']\n\nThe three variables that will be looked at are the ones in the season1 dataset that relate to total player load. For this purpose, 3 variables will be chosen/combined in a meaningful way for the graph. Here they are:\n\nIATS_IDTS_pct = IMA Accel Total and IMA Decel Total averaged\nJumps_pct = IMA Jump Count Low Band, IMA Jump Count Med Band, IMA Jump Count High Band averaged\nEES_pct =Explosive Efforts\n\nTo find the proportions, all 3 main variables will be divided by the Total Player Load at the matching dates.\n\n# Avg_IATS_IDTS_By_Date is the average of the IMA Accel/Decel total. Having both independently on the graph causes busy-ness\n# They're similar in correlation to total player load (found through EDA)\ndf1_copy['Avg_IATS_IDTS_By_Date'] = (\n    df1_copy['IMA Accel Total'] + \n    df1_copy['IMA Decel Total']\n    ) / 2\ndf1_copy['IATS_IDTS_pct'] = df1_copy['Avg_IATS_IDTS_By_Date'] / df1_copy['Total Player Load']\n\n# Avg_ijclb_ijcmb_ijchb_By_Date is the average of the IMA jump bands from low, medium, and high. Having all independently on the graph causes busy-ness\n# They're similar in correlation to total player load (found through EDA)\ndf1_copy['Avg_ijclb_ijcmb_ijchb_By_Date'] = (\n    df1_copy['IMA Jump Count Low Band'] +\n    df1_copy['IMA Jump Count Med Band'] +\n    df1_copy['IMA Jump Count High Band']\n    ) / 3\ndf1_copy['Jumps_pct'] = df1_copy['Avg_ijclb_ijcmb_ijchb_By_Date'] / df1_copy['Total Player Load']\n\n# Explosive Efforts can remain independent since there's only one \"version\"\ndf1_copy['EES_pct'] = df1_copy['Explosive Efforts'] / df1_copy['Total Player Load']\n\n\navg_df = df1_copy.groupby('Date')[[ 'IATS_IDTS_pct', 'EES_pct', 'Jumps_pct']].mean().reset_index()\navg_df.columns = ['Date',  'IATS_IDTS', 'EES', 'Jumps']\n\ncol_map = {\n    'IATS_IDTS': '#232D4B',\n    'EES': '#E57200',\n    'Jumps': '#D3D3D3'\n}\n\n\navg_df = avg_df.sort_values('Date')\nx = range(len(avg_df))\n\nplt.figure(figsize=(10, 5.8))\n\nplt.axhspan(0, 1.0, color='#bcbcbc', zorder=0)  # soft ivory/sand\n\nplt.stackplot(\n    avg_df['Date'],\n    avg_df['IATS_IDTS'],\n    avg_df['EES'],\n    avg_df['Jumps'],\n    colors=['#232D4B', '#E57200', '#fbc902'],\n    alpha=1\n)\n\n\nplt.gca().spines['top'].set_visible(False)\nplt.gca().spines['right'].set_visible(False)\nplt.gca().spines['left'].set_visible(False)\nplt.gca().spines['bottom'].set_visible(False)\nplt.tick_params(axis='y', length=0)\n\nhandles = [\n    Patch(facecolor='#D3D3D3'),  # Top layer in graph (Jumps)\n    Patch(facecolor='#E57200'),  # Middle layer (EES)\n    Patch(facecolor='#fbc902'),  # Bottom layer (IATS_IDTS)\n]\nlabels = [\n    'IMA Jump Band Counts',\n    'Explosive Efforts',\n    'IMA Accels & Decels'\n]\n\n# plt.legend(\n#     handles=handles,\n#     labels=labels,\n#     loc=\"upper right\",\n#     bbox_to_anchor=(1, 1.2),\n#     frameon=False,\n#     fontsize=8\n# )\n\nplt.text(0.44, 1.23, 'IMA Acceleration/Deceleration', transform=plt.gca().transAxes, fontsize=13, color='#000080')\nplt.text(0.097, 1.175, 'Explosive Efforts', transform=plt.gca().transAxes, fontsize=13, color='#E57200')\nplt.text(0.308, 1.175, 'IMA Jump Bands', transform=plt.gca().transAxes, fontsize=13, color='#fbc902')\n\n\n\nplt.xlabel('Game Dates')\nplt.text(-0.009, 1.04, \"(Cumulative Proportions of Total Player Load)\", transform=plt.gca().transAxes)\nplt.title(\"Total Player Load Contributors in Season 1 Games:                                                      contributes the most,\\nfollowed by                               and                \", x=-0.01, y=1.15, loc='left')\nplt.text(0, -0.15, 'Source: Season 1 data, Athlete H data', transform=plt.gca().transAxes)\n\n\nplt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=1)) \nplt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))\nplt.gca().xaxis.set_major_locator(mdates.AutoDateLocator())\n\nplt.xlim(avg_df['Date'].min(), avg_df['Date'].max())\n\nplt.tight_layout()\n\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "datacleaning.html#cleaning-the-dataset",
    "href": "datacleaning.html#cleaning-the-dataset",
    "title": "2  Data Cleaning",
    "section": "",
    "text": "2.1.1 Deleting unused columns\n\ndf1 = df1[['Date', 'About', 'Position', 'Period', 'Total Player Load', 'Player Load Per Minute', 'IMA Accel Total', \n           'IMA Decel Total', 'IMA Jump Count Low Band', 'IMA Jump Count Med Band', 'IMA Jump Count High Band', 'Explosive Efforts']]\n\ndf2 = df2[['Date', 'About', 'Position', 'Period', 'Total Player Load', 'Player Load Per Minute', 'IMA Accel Total', \n           'IMA Decel Total', 'IMA Jump Count Low Band', 'IMA Jump Count Med Band', 'IMA Jump Count High Band', 'Explosive Efforts']]\n\n# make sure columns dropped properly\nprint(\"df1:\", df1.columns)\nprint(\"df2:\", df2.columns)\n\ndf1: Index(['Date', 'About', 'Position', 'Period', 'Total Player Load',\n       'Player Load Per Minute', 'IMA Accel Total', 'IMA Decel Total',\n       'IMA Jump Count Low Band', 'IMA Jump Count Med Band',\n       'IMA Jump Count High Band', 'Explosive Efforts'],\n      dtype='object')\ndf2: Index(['Date', 'About', 'Position', 'Period', 'Total Player Load',\n       'Player Load Per Minute', 'IMA Accel Total', 'IMA Decel Total',\n       'IMA Jump Count Low Band', 'IMA Jump Count Med Band',\n       'IMA Jump Count High Band', 'Explosive Efforts'],\n      dtype='object')\n\n\n\n\n2.1.2 Check for Missing Data\n\n# looking for missing values in the columns \n# loop through each column and print the percentage of missing values of each column\nprint(\"Season1 Missings:\")\nfor col in df1.columns:\n    total = len(df1)\n    missing = df1[col].isnull().sum()\n    percent = (missing / total) * 100\n    print(col , \":\", round(percent, 2))\n\nprint(\"\\nSeason2 Missings:\")\nfor col in df2.columns:\n    total = len(df2)\n    missing = df2[col].isnull().sum()\n    percent = (missing / total) * 100\n    print(col , \":\", round(percent, 2))\n\nSeason1 Missings:\nDate : 0.0\nAbout : 0.0\nPosition : 0.0\nPeriod : 0.0\nTotal Player Load : 0.0\nPlayer Load Per Minute : 0.0\nIMA Accel Total : 0.0\nIMA Decel Total : 0.0\nIMA Jump Count Low Band : 0.0\nIMA Jump Count Med Band : 0.0\nIMA Jump Count High Band : 0.0\nExplosive Efforts : 0.0\n\nSeason2 Missings:\nDate : 0.0\nAbout : 0.0\nPosition : 0.0\nPeriod : 0.0\nTotal Player Load : 0.0\nPlayer Load Per Minute : 0.0\nIMA Accel Total : 0.0\nIMA Decel Total : 0.0\nIMA Jump Count Low Band : 0.0\nIMA Jump Count Med Band : 0.0\nIMA Jump Count High Band : 0.0\nExplosive Efforts : 0.0\n\n\n\n\n2.1.3 Check for Duplicated/Correct Data Types in df1\n\n# using .unique() to check for duplicates because of spaces/wrong data types/etc\n# print(df1['Date'].unique() , \"\\n\", df1['Date'].dtype) # -&gt; all objects, no duplicates\n# print(df1['About'].unique() , \"\\n\", df1['About'].dtype) # -&gt; all objects, no duplicates\nprint(df1['Position'].unique() , \"\\n\", df1['Position'].dtype) # -&gt; all objects, no duplicates\n\n['Guard' 'Forward' 'Center'] \n object\n\n\nWe see that there is one player whose name is not in the correct format of ‘Athlete ..’, so we will replace his name with ‘Athlete K’ per instructions.\n\ndf1['About'] = df1['About'].replace('Ben Vander Plas', 'Athlete K')\ndf1['About'].unique()\n\narray(['Athlete I', 'Athlete G', 'Athlete A', 'Athlete F', 'Athlete H',\n       'Athlete B', 'Athlete K', 'Athlete M', 'Athlete C', 'Athlete D',\n       'Athlete L', 'Athlete J', 'Athlete E'], dtype=object)\n\n\nWe only want to look at data for game-related observations, so we are only keeping rows where “Period 1” and “Period 2” are the Period type.\n\n# Period 1, Period 2\nkrows = []\n\nfor i in range(len(df1)):\n    value = str(df1.loc[i, 'Period'])\n    if 'Period 1' in value or 'Period 2' in value:\n        krows.append(i)\ndf1 = df1.loc[krows].reset_index(drop=True)\n\nBe more specific when dropping rows now, since some of the rows kept did include “Period 1”, but were actually a Scrimmage Period 1, not a game.\n\n# delete rows with \"Scrimmage\"\ndrows = []\n\nfor i in range(len(df1)):\n    value = str(df1.loc[i, 'Period'])\n    if 'Scrimmage' in value:\n        drows.append(i)\n    if 'Drill' in value:\n        drows.append(i)\n\ndf1.drop(index=drows, inplace=True)\ndf1.reset_index(drop=True, inplace=True)\n\ndf1['Period'].value_counts()\n\nPeriod\n3. Period 2    139\n3. Period 1    139\n2. Period 1    136\n4. Period 2    130\n2. Period 2      4\nName: count, dtype: int64\n\n\nTo finish cleaning the Period column, we are going to make sure that there are no duplicates in this column. Since some of these duplicates included a period number in the Period value, we will remove them to make them all merge into only two unique values.\n\n# Period 1 = 1, Period 2 = 2\n\n# cleaning Period 1\nif \"2. Period 1\" in df1['Period'].values:\n    df1['Period'] = df1['Period'].replace(\"2. Period 1\", \"Period 1\")\nif \"3. Period 1\" in df1['Period'].values:\n    df1['Period'] = df1['Period'].replace(\"3. Period 1\", \"Period 1\")\n\n# cleaning Period 2\nif \"2. Period 2\" in df1['Period'].values:\n    df1['Period'] = df1['Period'].replace(\"2. Period 2\", \"Period 2\")\nif \"4. Period 2\" in df1['Period'].values:\n    df1['Period'] = df1['Period'].replace(\"4. Period 2\", \"Period 2\")\nif \"3. Period 2\" in df1['Period'].values:\n    df1['Period'] = df1['Period'].replace(\"3. Period 2\", \"Period 2\")\n\nprint(df1['Period'].value_counts())\n\nPeriod\nPeriod 1    275\nPeriod 2    273\nName: count, dtype: int64\n\n\nContinuing to check the columns:\n\n# # print(df1['Total Player Load'].value_counts(), \"\\n\", df1['Total Player Load'].dtype) # -&gt; all floats\n# # print(df1['Player Load Per Minute'].unique(), \"\\n\", df1['Player Load Per Minute'].dtype) # -&gt; all floats w/ one decimal place\n# # print(df1['IMA Accel Total'].unique(), \"\\n\", df1['IMA Accel Total'].dtype) # -&gt; all ints, no duplicates\n# # print(df1['IMA Decel Total'].unique(), \"\\n\", df1['IMA Decel Total'].dtype) # -&gt; all ints, no duplicates \n# print(df1['IMA Jump Count Low Band'].unique(), \"\\n\", df1['IMA Jump Count Low Band'].dtype) # -&gt; all ints, no duplicates\n# print(df1['IMA Jump Count Med Band'].unique(), \"\\n\", df1['IMA Jump Count Med Band'].dtype) # -&gt; all ints, no duplicates\n# print(df1['IMA Jump Count High Band'].unique(), \"\\n\", df1['IMA Jump Count High Band'].dtype) # -&gt; all ints, no duplicates\nprint(df1['Explosive Efforts'].unique(), \"\\n\", df1['Explosive Efforts'].dtype) # -&gt; all ints, no duplicates\n\n[40 50 54 30  4 26 33 20 29 10 43 37 44 12 27 22  5 31 21 36 34 39 58 32\n 38 19 45 42 49  6 18 59 56 25 13 23 24 35  1 41 60 52 11  0 47 14 57  8\n 72  2  7 17  9 28 46 62 69 15 16 51 61 53  3 63 71 48 81 55 66 64 65] \n int64\n\n\n\n\n2.1.4 Check for Duplicates/Correct Data Types in df2:\nOnce again, we can use the .unique() and .value_counts() functions to check for duplicates that might be caused by spaces or change in data types.\n\n# print(df2['Date'].unique() , \"\\n\", df2['Date'].dtype) # -&gt; all objects, no duplicates\n# print(df2['About'].unique() , \"\\n\", df2['About'].dtype) # -&gt; all objects, no duplicates\nprint(df2['Position'].unique() , \"\\n\", df2['Position'].dtype) # -&gt; all objects, no duplicates\n\n['Forward' 'Guard' 'Center'] \n object\n\n\nWe only want to look at data for game-related observations, so we are only keeping rows where “Period 1” and “Period 2” are the Period type.\n\n# Period 1, Period 2\nkrows = []\n\nfor i in range(len(df2)):\n    value = str(df2.loc[i, 'Period'])\n    if 'Period 1' in value or 'Period 2' in value:\n        krows.append(i)\ndf2 = df2.loc[krows].reset_index(drop=True)\n\nBe more specific when dropping rows now, since some of the rows kept did include “Period 1”, but were actually a Scrimmage Period 1 not a game.\n\n# delete rows with \"Scrimmage\"\ndrows = []\n\nfor i in range(len(df2)):\n    value = str(df2.loc[i, 'Period'])\n    if 'Scrimmage' in value:\n        drows.append(i)\n    if 'Drill' in value:\n        drows.append(i)\n\ndf2.drop(index=drows, inplace=True)\ndf2.reset_index(drop=True, inplace=True)\n\ndf2['Period'].value_counts()\n\nPeriod\n3. Period 1    177\n2. Period 1    138\n3. Period 2    135\n4. Period 2     86\n5. Period 2     86\n8. Period 1     13\n9. Period 2     13\n2. Period 2      9\n1. Period 1      1\nName: count, dtype: int64\n\n\nTo finish cleaning the Period column, we are going to make sure that there are no duplicates in this column. Since some of these duplicates included a period number in the Period value, we will remove them to make them all merge into only two unique values.\n\n# Period 1 = 1, Period 2 = 2\n\n# cleaning Period 1\nif \"2. Period 1\" in df2['Period'].values:\n    df2['Period'] = df2['Period'].replace(\"2. Period 1\", \"Period 1\")\nif \"3. Period 1\" in df2['Period'].values:\n    df2['Period'] = df2['Period'].replace(\"3. Period 1\", \"Period 1\")\nif \"1. Period 1\" in df2['Period'].values:\n    df2['Period'] = df2['Period'].replace(\"1. Period 1\", \"Period 1\")\nif \"8. Period 1\" in df2['Period'].values:\n    df2['Period'] = df2['Period'].replace(\"8. Period 1\", \"Period 1\")\n\n# cleaning Period 2\nif \"2. Period 2\" in df2['Period'].values:\n    df2['Period'] = df2['Period'].replace(\"2. Period 2\", \"Period 2\")\nif \"4. Period 2\" in df2['Period'].values:\n    df2['Period'] = df2['Period'].replace(\"4. Period 2\", \"Period 2\")\nif \"3. Period 2\" in df2['Period'].values:\n    df2['Period'] = df2['Period'].replace(\"3. Period 2\", \"Period 2\")\nif \"5. Period 2\" in df2['Period'].values:\n    df2['Period'] = df2['Period'].replace(\"5. Period 2\", \"Period 2\")\nif \"9. Period 2\" in df2['Period'].values:\n    df2['Period'] = df2['Period'].replace(\"9. Period 2\", \"Period 2\")\n\nelse:\n    df2['Period'] = df2['Period']\n\nprint(df2['Period'].value_counts())\n\nPeriod\nPeriod 1    329\nPeriod 2    329\nName: count, dtype: int64\n\n\nContinuing to check the columns:\n\n# print(df2['Total Player Load'].value_counts(), \"\\n\", df2['Total Player Load'].dtype) # -&gt; all floats\n# print(df2['Player Load Per Minute'].unique(), \"\\n\", df2['Player Load Per Minute'].dtype) # -&gt; all floats w/ one decimal place\n# print(df2['IMA Accel Total'].unique(), \"\\n\", df2['IMA Accel Total'].dtype) # -&gt; all ints, no duplicates\n# print(df2['IMA Decel Total'].unique(), \"\\n\", df2['IMA Decel Total'].dtype) # -&gt; all ints, no duplicates \n# print(df2['IMA Jump Count Low Band'].unique(), \"\\n\", df2['IMA Jump Count Low Band'].dtype) # -&gt; all ints, no duplicates\n# print(df2['IMA Jump Count Med Band'].unique(), \"\\n\", df2['IMA Jump Count Med Band'].dtype) # -&gt; all ints, no duplicates\n# print(df2['IMA Jump Count High Band'].unique(), \"\\n\", df2['IMA Jump Count High Band'].dtype) # -&gt; all ints, no duplicates\nprint(df2['Explosive Efforts'].unique(), \"\\n\", df2['Explosive Efforts'].dtype) # -&gt; all ints, no duplicates\n\n[19 23  8  7 42 34 32 25 18 22 20  2  3 33 26 27  5  9 11  6 43 30 35 29\n 17 21 14  0 50 13 31 10 15 24 52 61 28 36 16 45 49 56 46  4 65 12 40 67\n 44 39 41 38 62 37 60 47 54 48 55 57 51 66 53 58 64] \n int64\n\n\nFor future use, like making our graphs and other analysis, we want to save the cleaned data sets as new csv files.\n\ndf1.to_csv(\"./season1_cleaned.csv\", index=False)\ndf2.to_csv(\"./season2_cleaned.csv\", index=False)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Cleaning</span>"
    ]
  },
  {
    "objectID": "datacleaning.html#deleting-unused-columns",
    "href": "datacleaning.html#deleting-unused-columns",
    "title": "2  Data Cleaning",
    "section": "2.2 Deleting unused columns",
    "text": "2.2 Deleting unused columns\n\ndf1 = df1[['Date', 'About', 'Position', 'Period', 'Total Player Load', 'Player Load Per Minute', 'IMA Accel Total', \n           'IMA Decel Total', 'IMA Jump Count Low Band', 'IMA Jump Count Med Band', 'IMA Jump Count High Band', 'Explosive Efforts']]\n\ndf2 = df2[['Date', 'About', 'Position', 'Period', 'Total Player Load', 'Player Load Per Minute', 'IMA Accel Total', \n           'IMA Decel Total', 'IMA Jump Count Low Band', 'IMA Jump Count Med Band', 'IMA Jump Count High Band', 'Explosive Efforts']]\n\n# make sure columns dropped properly\nprint(\"df1:\", df1.columns)\nprint(\"df2:\", df2.columns)\n\ndf1: Index(['Date', 'About', 'Position', 'Period', 'Total Player Load',\n       'Player Load Per Minute', 'IMA Accel Total', 'IMA Decel Total',\n       'IMA Jump Count Low Band', 'IMA Jump Count Med Band',\n       'IMA Jump Count High Band', 'Explosive Efforts'],\n      dtype='object')\ndf2: Index(['Date', 'About', 'Position', 'Period', 'Total Player Load',\n       'Player Load Per Minute', 'IMA Accel Total', 'IMA Decel Total',\n       'IMA Jump Count Low Band', 'IMA Jump Count Med Band',\n       'IMA Jump Count High Band', 'Explosive Efforts'],\n      dtype='object')",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Cleaning</span>"
    ]
  },
  {
    "objectID": "datacleaning.html#check-for-missing-data",
    "href": "datacleaning.html#check-for-missing-data",
    "title": "2  Data Cleaning",
    "section": "2.3 Check for Missing Data",
    "text": "2.3 Check for Missing Data\n\n# looking for missing values in the columns \n# loop through each column and print the percentage of missing values of each column\nprint(\"Season1 Missings:\")\nfor col in df1.columns:\n    total = len(df1)\n    missing = df1[col].isnull().sum()\n    percent = (missing / total) * 100\n    print(col , \":\", round(percent, 2))\n\nprint(\"\\nSeason2 Missings:\")\nfor col in df2.columns:\n    total = len(df2)\n    missing = df2[col].isnull().sum()\n    percent = (missing / total) * 100\n    print(col , \":\", round(percent, 2))\n\nSeason1 Missings:\nDate : 0.0\nAbout : 0.0\nPosition : 0.0\nPeriod : 0.0\nTotal Player Load : 0.0\nPlayer Load Per Minute : 0.0\nIMA Accel Total : 0.0\nIMA Decel Total : 0.0\nIMA Jump Count Low Band : 0.0\nIMA Jump Count Med Band : 0.0\nIMA Jump Count High Band : 0.0\nExplosive Efforts : 0.0\n\nSeason2 Missings:\nDate : 0.0\nAbout : 0.0\nPosition : 0.0\nPeriod : 0.0\nTotal Player Load : 0.0\nPlayer Load Per Minute : 0.0\nIMA Accel Total : 0.0\nIMA Decel Total : 0.0\nIMA Jump Count Low Band : 0.0\nIMA Jump Count Med Band : 0.0\nIMA Jump Count High Band : 0.0\nExplosive Efforts : 0.0",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Cleaning</span>"
    ]
  },
  {
    "objectID": "datacleaning.html#check-for-duplicatescorrect-data-types-in-df2",
    "href": "datacleaning.html#check-for-duplicatescorrect-data-types-in-df2",
    "title": "2  Data Cleaning",
    "section": "2.5 Check for Duplicates/Correct Data Types in df2:",
    "text": "2.5 Check for Duplicates/Correct Data Types in df2:\nOnce again, we can use the .unique() and .value_counts() functions to check for duplicates that might be caused by spaces or change in data types.\n\n# print(df2['Date'].unique() , \"\\n\", df2['Date'].dtype) # -&gt; all objects, no duplicates\n# print(df2['About'].unique() , \"\\n\", df2['About'].dtype) # -&gt; all objects, no duplicates\nprint(df2['Position'].unique() , \"\\n\", df2['Position'].dtype) # -&gt; all objects, no duplicates\n\n['Forward' 'Guard' 'Center'] \n object\n\n\nWe only want to look at data for game-related observations, so we are only keeping rows where “Period 1” and “Period 2” are the Period type.\n\n# Period 1, Period 2\nkrows = []\n\nfor i in range(len(df2)):\n    value = str(df2.loc[i, 'Period'])\n    if 'Period 1' in value or 'Period 2' in value:\n        krows.append(i)\ndf2 = df2.loc[krows].reset_index(drop=True)\n\nBe more specific when dropping rows now, since some of the rows kept did include “Period 1”, but were actually a Scrimmage Period 1 not a game.\n\n# delete rows with \"Scrimmage\"\ndrows = []\n\nfor i in range(len(df2)):\n    value = str(df2.loc[i, 'Period'])\n    if 'Scrimmage' in value:\n        drows.append(i)\n    if 'Drill' in value:\n        drows.append(i)\n\ndf2.drop(index=drows, inplace=True)\ndf2.reset_index(drop=True, inplace=True)\n\ndf2['Period'].value_counts()\n\nPeriod\n3. Period 1    177\n2. Period 1    138\n3. Period 2    135\n4. Period 2     86\n5. Period 2     86\n8. Period 1     13\n9. Period 2     13\n2. Period 2      9\n1. Period 1      1\nName: count, dtype: int64\n\n\nTo finish cleaning the Period column, we are going to make sure that there are no duplicates in this column. Since some of these duplicates included a period number in the Period value, we will remove them to make them all merge into only two unique values.\n\n# Period 1 = 1, Period 2 = 2\n\n# cleaning Period 1\nif \"2. Period 1\" in df2['Period'].values:\n    df2['Period'] = df2['Period'].replace(\"2. Period 1\", \"Period 1\")\nif \"3. Period 1\" in df2['Period'].values:\n    df2['Period'] = df2['Period'].replace(\"3. Period 1\", \"Period 1\")\nif \"1. Period 1\" in df2['Period'].values:\n    df2['Period'] = df2['Period'].replace(\"1. Period 1\", \"Period 1\")\nif \"8. Period 1\" in df2['Period'].values:\n    df2['Period'] = df2['Period'].replace(\"8. Period 1\", \"Period 1\")\n\n# cleaning Period 2\nif \"2. Period 2\" in df2['Period'].values:\n    df2['Period'] = df2['Period'].replace(\"2. Period 2\", \"Period 2\")\nif \"4. Period 2\" in df2['Period'].values:\n    df2['Period'] = df2['Period'].replace(\"4. Period 2\", \"Period 2\")\nif \"3. Period 2\" in df2['Period'].values:\n    df2['Period'] = df2['Period'].replace(\"3. Period 2\", \"Period 2\")\nif \"5. Period 2\" in df2['Period'].values:\n    df2['Period'] = df2['Period'].replace(\"5. Period 2\", \"Period 2\")\nif \"9. Period 2\" in df2['Period'].values:\n    df2['Period'] = df2['Period'].replace(\"9. Period 2\", \"Period 2\")\n\nelse:\n    df2['Period'] = df2['Period']\n\nprint(df2['Period'].value_counts())\n\nPeriod\nPeriod 1    329\nPeriod 2    329\nName: count, dtype: int64\n\n\nContinuing to check the columns:\n\n# print(df2['Total Player Load'].value_counts(), \"\\n\", df2['Total Player Load'].dtype) # -&gt; all floats\n# print(df2['Player Load Per Minute'].unique(), \"\\n\", df2['Player Load Per Minute'].dtype) # -&gt; all floats w/ one decimal place\n# print(df2['IMA Accel Total'].unique(), \"\\n\", df2['IMA Accel Total'].dtype) # -&gt; all ints, no duplicates\n# print(df2['IMA Decel Total'].unique(), \"\\n\", df2['IMA Decel Total'].dtype) # -&gt; all ints, no duplicates \n# print(df2['IMA Jump Count Low Band'].unique(), \"\\n\", df2['IMA Jump Count Low Band'].dtype) # -&gt; all ints, no duplicates\n# print(df2['IMA Jump Count Med Band'].unique(), \"\\n\", df2['IMA Jump Count Med Band'].dtype) # -&gt; all ints, no duplicates\n# print(df2['IMA Jump Count High Band'].unique(), \"\\n\", df2['IMA Jump Count High Band'].dtype) # -&gt; all ints, no duplicates\nprint(df2['Explosive Efforts'].unique(), \"\\n\", df2['Explosive Efforts'].dtype) # -&gt; all ints, no duplicates\n\n[19 23  8  7 42 34 32 25 18 22 20  2  3 33 26 27  5  9 11  6 43 30 35 29\n 17 21 14  0 50 13 31 10 15 24 52 61 28 36 16 45 49 56 46  4 65 12 40 67\n 44 39 41 38 62 37 60 47 54 48 55 57 51 66 53 58 64] \n int64\n\n\nFor future use, like making our graphs and other analysis, we want to save the cleaned data sets as new csv files.\n\ndf1.to_csv(\"./season1_cleaned.csv\", index=False)\ndf2.to_csv(\"./season2_cleaned.csv\", index=False)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Cleaning</span>"
    ]
  },
  {
    "objectID": "datacleaning.html#check-for-duplicatedcorrect-data-types-in-df1",
    "href": "datacleaning.html#check-for-duplicatedcorrect-data-types-in-df1",
    "title": "2  Data Cleaning",
    "section": "2.4 Check for Duplicated/Correct Data Types in df1",
    "text": "2.4 Check for Duplicated/Correct Data Types in df1\n\n# using .unique() to check for duplicates because of spaces/wrong data types/etc\n# print(df1['Date'].unique() , \"\\n\", df1['Date'].dtype) # -&gt; all objects, no duplicates\n# print(df1['About'].unique() , \"\\n\", df1['About'].dtype) # -&gt; all objects, no duplicates\nprint(df1['Position'].unique() , \"\\n\", df1['Position'].dtype) # -&gt; all objects, no duplicates\n\n['Guard' 'Forward' 'Center'] \n object\n\n\nWe see that there is one player whose name is not in the correct format of ‘Athlete ..’, so we will replace his name with ‘Athlete K’ per instructions.\n\ndf1['About'] = df1['About'].replace('Ben Vander Plas', 'Athlete K')\ndf1['About'].unique()\n\narray(['Athlete I', 'Athlete G', 'Athlete A', 'Athlete F', 'Athlete H',\n       'Athlete B', 'Athlete K', 'Athlete M', 'Athlete C', 'Athlete D',\n       'Athlete L', 'Athlete J', 'Athlete E'], dtype=object)\n\n\nWe only want to look at data for game-related observations, so we are only keeping rows where “Period 1” and “Period 2” are the Period type.\n\n# Period 1, Period 2\nkrows = []\n\nfor i in range(len(df1)):\n    value = str(df1.loc[i, 'Period'])\n    if 'Period 1' in value or 'Period 2' in value:\n        krows.append(i)\ndf1 = df1.loc[krows].reset_index(drop=True)\n\nBe more specific when dropping rows now, since some of the rows kept did include “Period 1”, but were actually a Scrimmage Period 1, not a game.\n\n# delete rows with \"Scrimmage\"\ndrows = []\n\nfor i in range(len(df1)):\n    value = str(df1.loc[i, 'Period'])\n    if 'Scrimmage' in value:\n        drows.append(i)\n    if 'Drill' in value:\n        drows.append(i)\n\ndf1.drop(index=drows, inplace=True)\ndf1.reset_index(drop=True, inplace=True)\n\ndf1['Period'].value_counts()\n\nPeriod\n3. Period 2    139\n3. Period 1    139\n2. Period 1    136\n4. Period 2    130\n2. Period 2      4\nName: count, dtype: int64\n\n\nTo finish cleaning the Period column, we are going to make sure that there are no duplicates in this column. Since some of these duplicates included a period number in the Period value, we will remove them to make them all merge into only two unique values.\n\n# Period 1 = 1, Period 2 = 2\n\n# cleaning Period 1\nif \"2. Period 1\" in df1['Period'].values:\n    df1['Period'] = df1['Period'].replace(\"2. Period 1\", \"Period 1\")\nif \"3. Period 1\" in df1['Period'].values:\n    df1['Period'] = df1['Period'].replace(\"3. Period 1\", \"Period 1\")\n\n# cleaning Period 2\nif \"2. Period 2\" in df1['Period'].values:\n    df1['Period'] = df1['Period'].replace(\"2. Period 2\", \"Period 2\")\nif \"4. Period 2\" in df1['Period'].values:\n    df1['Period'] = df1['Period'].replace(\"4. Period 2\", \"Period 2\")\nif \"3. Period 2\" in df1['Period'].values:\n    df1['Period'] = df1['Period'].replace(\"3. Period 2\", \"Period 2\")\n\nprint(df1['Period'].value_counts())\n\nPeriod\nPeriod 1    275\nPeriod 2    273\nName: count, dtype: int64\n\n\nContinuing to check the columns:\n\n# # print(df1['Total Player Load'].value_counts(), \"\\n\", df1['Total Player Load'].dtype) # -&gt; all floats\n# # print(df1['Player Load Per Minute'].unique(), \"\\n\", df1['Player Load Per Minute'].dtype) # -&gt; all floats w/ one decimal place\n# # print(df1['IMA Accel Total'].unique(), \"\\n\", df1['IMA Accel Total'].dtype) # -&gt; all ints, no duplicates\n# # print(df1['IMA Decel Total'].unique(), \"\\n\", df1['IMA Decel Total'].dtype) # -&gt; all ints, no duplicates \n# print(df1['IMA Jump Count Low Band'].unique(), \"\\n\", df1['IMA Jump Count Low Band'].dtype) # -&gt; all ints, no duplicates\n# print(df1['IMA Jump Count Med Band'].unique(), \"\\n\", df1['IMA Jump Count Med Band'].dtype) # -&gt; all ints, no duplicates\n# print(df1['IMA Jump Count High Band'].unique(), \"\\n\", df1['IMA Jump Count High Band'].dtype) # -&gt; all ints, no duplicates\nprint(df1['Explosive Efforts'].unique(), \"\\n\", df1['Explosive Efforts'].dtype) # -&gt; all ints, no duplicates\n\n[40 50 54 30  4 26 33 20 29 10 43 37 44 12 27 22  5 31 21 36 34 39 58 32\n 38 19 45 42 49  6 18 59 56 25 13 23 24 35  1 41 60 52 11  0 47 14 57  8\n 72  2  7 17  9 28 46 62 69 15 16 51 61 53  3 63 71 48 81 55 66 64 65] \n int64",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Cleaning</span>"
    ]
  }
]